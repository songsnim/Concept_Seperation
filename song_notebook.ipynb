{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날짜 : 2022-02-09\n",
      "GPU device : cuda:2\n",
      "image.size() =  torch.Size([128, 1, 32, 32]) \ttype torch.FloatTensor\n",
      "label.size() =  torch.Size([128]) \ttype torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "args = {\n",
    "        'GPU_NUM' : 2,\n",
    "        'Epochs' : 200,\n",
    "        'batch_size' : 128,\n",
    "        'lr' : 0.0002,\n",
    "        'b1' : 0.5,\n",
    "        'b2' : 0.999,\n",
    "        'latent_dim' : 62,\n",
    "        'code_dim' : 2,\n",
    "        'n_classes' : 2,\n",
    "        'img_size' : 32,\n",
    "        'channels' : 1,\n",
    "        'sample_interval' : 400\n",
    "        }\n",
    "\n",
    "device = torch.device('cuda:{}'.format(args['GPU_NUM']) if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "today = datetime.date.today()\n",
    "print('오늘 날짜 :',today)\n",
    "print('GPU device :', device)\n",
    "\n",
    "my_transform =transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(args['img_size']), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_data = ImageFolder('MNIST/classes/binary/train', transform = my_transform)\n",
    "test_data = ImageFolder('MNIST/classes/binary/test', transform = my_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=args['batch_size'], shuffle=True)\n",
    "\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10*pltsize,pltsize))\n",
    "for image, label in train_loader:\n",
    "    print('image.size() = ',image.size(), '\\ttype', image.type())\n",
    "    print('label.size() = ', label.size(), '\\ttype', label.type())\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(10*pltsize,pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image[i,:,:,:].permute(1,2,0), cmap=\"gray\")\n",
    "    plt.title('class '+ str(label[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    \"\"\" Conv layer는 mean이 0, std가 0.02인 가우시안 분포로 weight init\n",
    "        BatchNorm은 mean이 1, std가 0.02인 가우시안 분포로 weight init\n",
    "        Bias term은 전부 0으로 초기화\n",
    "    Args:\n",
    "        m ([model]): 학습하려는 모델\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def to_discrete(y, num_columns):\n",
    "    \"\"\" onehot encoding\n",
    "        (batch_size,)가 shape인 label이 있으면, (64,num_columns)인 zeros 행렬을 생성하고,\n",
    "        (batch_size,)의 label vector element 값의 index만 1로 바꿔서 one-hot encoding함\n",
    "    Args:\n",
    "        y : 어떤 array (y.shape[0]는 batch_size로 보면 됨)\n",
    "        num_columns : num_classes\n",
    "    \"\"\"\n",
    "    y_disc = np.zeros((y.shape[0], num_columns))\n",
    "    y_disc[range(y.shape[0]), y] = 1.0 # one-hot encoding()\n",
    "\n",
    "    return Variable(FloatTensor(y_disc))\n",
    "\n",
    "def sample_image(epoch):\n",
    "    folder_path = datetime.date.today()\n",
    "    os.makedirs('samples/{}_{}'.format(folder_path,args['description']), exist_ok=True)\n",
    "\n",
    "    zeros = torch.zeros((10,1)).to(device)\n",
    "    inter = torch.linspace(-2,2,10).unsqueeze(1).to(device)\n",
    "    inter_p = torch.cat([inter, zeros, zeros], dim=-1).to(device)\n",
    "    inter_g1 = torch.cat([zeros, inter, zeros], dim=-1).to(device)\n",
    "    inter_g2 = torch.cat([zeros, zeros, inter], dim=-1).to(device)\n",
    "    \n",
    "    # one !!\n",
    "    _, _, latent = M(E(image_one))\n",
    "    label_one = torch.tensor([1,0], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    one_repeat = label_one.repeat(10,1).to(device)\n",
    "    one_latent_repeat = latent.repeat(10,1).to(device)\n",
    "    one_p = G(one_repeat,inter_g1[:,0].unsqueeze(1), inter_p[:,1:], one_latent_repeat)\n",
    "    one_g1 = G(one_repeat, inter_g1[:,0].unsqueeze(1), inter_g1[:,1:], one_latent_repeat)\n",
    "    one_g2 = G(one_repeat, inter_g2[:,0].unsqueeze(1), inter_g2[:,1:], one_latent_repeat)\n",
    "    sample_one = torch.cat([image_one,one_p, image_one,one_g1, image_one,one_g2], dim=0).to(device)\n",
    "\n",
    "    # seven!!!\n",
    "    _, _, latent = M(E(image_seven))\n",
    "    label_seven = torch.tensor([0,1], dtype=torch.int64, device=device).unsqueeze(0)\n",
    "    seven_repeat = label_seven.repeat(10,1).to(device)\n",
    "    seven_latent_repeat = latent.repeat(10,1).to(device)\n",
    "    seven_p = G(seven_repeat, inter_g1[:,0].unsqueeze(1), inter_g1[:,1:], seven_latent_repeat)\n",
    "    seven_g1 = G(seven_repeat, inter_g1[:,0].unsqueeze(1), inter_g1[:,1:], seven_latent_repeat)\n",
    "    seven_g2 = G(seven_repeat, inter_g2[:,0].unsqueeze(1), inter_g2[:,1:], seven_latent_repeat)\n",
    "    sample_seven = torch.cat([image_seven,seven_p,image_seven,seven_g1, image_seven,seven_g2], dim=0).to(device)\n",
    "    \n",
    "    sample = torch.cat([sample_one,sample_seven], dim=0).to(device)\n",
    "        \n",
    "    grid = torchvision.utils.make_grid(sample, nrow=11, normalize=True)\n",
    "    \n",
    "    save_image(grid, 'samples/{}_{}/grid_{}.png'.format(folder_path,args['description'],epoch))\n",
    "    \n",
    "    return sample, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_loss = nn.CrossEntropyLoss().to(device)\n",
    "recon_loss = nn.MSELoss().to(device)\n",
    "adversarial_loss = nn.MSELoss().to(device)\n",
    "discrete_loss = nn.CrossEntropyLoss().to(device)\n",
    "code_loss = nn.MSELoss().to(device)\n",
    "# code_loss_P = nn.MSELoss().to(device)\n",
    "# pred_P_D_loss = nn.L1Loss().to(device)\n",
    "\n",
    "lambda_disc = 1\n",
    "lambda_code = 0.5\n",
    "args['description'] = 'info_loss_backward_after_50_epoch'\n",
    "from pretrain_ResNet import ResNet_3232\n",
    "pretrained_resnet = ResNet_3232(channels=1, num_classes=2).to(device)\n",
    "pretrained_resnet.load_state_dict(torch.load('pretrained_model/ResNet_3232_parameters_1_7.pt'))\n",
    "\n",
    "from Networks import Mapper, Predictor, Generator, Discriminator\n",
    "args['code_P_dim'] = 1\n",
    "args['code_G_dim'] = 2\n",
    "args['disc_dim'] = 2\n",
    "args['latent_dim'] = 32\n",
    "args['reduced_dim'] = args['code_P_dim'] + args['code_G_dim'] + args['latent_dim'] # 35\n",
    "\n",
    "E = nn.Sequential(*(list(pretrained_resnet.children())[:5])).to(device)\n",
    "M = Mapper(args).to(device)\n",
    "P = Predictor(args).to(device)\n",
    "G = Generator(args).to(device)\n",
    "D = Discriminator(args).to(device)\n",
    "\n",
    "\n",
    "M.apply(weights_init_normal)\n",
    "P.apply(weights_init_normal)\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizer_P = torch.optim.Adam(itertools.chain(M.parameters(),P.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(M.parameters(),G.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_D = torch.optim.Adam(itertools.chain(M.parameters(),D.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_info = torch.optim.Adam(itertools.chain(M.parameters(), P.parameters(),G.parameters(), D.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "# optimizer_info_P = torch.optim.Adam(itertools.chain(M.parameters(), P.parameters(), G.parameters(), D.parameters()), \n",
    "#                                     lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if (device == 'cuda:{}'.format(args['GPU_NUM'])) else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if (device == 'cuda:{}'.format(args['GPU_NUM'])) else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_loader:\n",
    "#     x = x.to(device)\n",
    "#     y = y.to(device)\n",
    "#     break\n",
    "\n",
    "# plt.figure(figsize=(15,12))\n",
    "# for idx in range(20):\n",
    "#     plt.subplot(4,5,idx+1)\n",
    "#     plt.axis('off')\n",
    "#     plt.title('idx={}, label={}'.format(idx, y[idx].item()))\n",
    "#     plt.imshow(to_np(x[idx].permute(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/song/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [acc : 99.62] [P : 0.1502] [D : 0.2341] [G : 9.3603] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 13.5]\n",
      "[Epoch 1/200] [acc : 99.50] [P : 0.0266] [D : 0.2347] [G : 5.2739] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 25.0]\n",
      "[Epoch 2/200] [acc : 99.73] [P : 0.0135] [D : 0.2477] [G : 4.6563] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 36.2]\n",
      "[Epoch 3/200] [acc : 99.65] [P : 0.0062] [D : 0.2286] [G : 4.9929] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 46.9]\n",
      "[Epoch 4/200] [acc : 99.54] [P : 0.0047] [D : 0.1900] [G : 3.7505] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 58.2]\n",
      "[Epoch 5/200] [acc : 99.46] [P : 0.0033] [D : 0.2404] [G : 4.2098] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 69.0]\n",
      "[Epoch 6/200] [acc : 99.65] [P : 0.0036] [D : 0.1756] [G : 5.2541] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 79.7]\n",
      "[Epoch 7/200] [acc : 99.62] [P : 0.0071] [D : 0.2480] [G : 4.3476] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 90.8]\n",
      "[Epoch 8/200] [acc : 99.62] [P : 0.0736] [D : 0.1017] [G : 4.9967] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 101.9]\n",
      "[Epoch 9/200] [acc : 99.62] [P : 0.0144] [D : 0.2242] [G : 4.6041] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 112.7]\n",
      "[Epoch 10/200] [acc : 99.58] [P : 0.0022] [D : 0.1679] [G : 4.0550] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 123.5]\n",
      "[Epoch 11/200] [acc : 99.65] [P : 0.0012] [D : 0.2353] [G : 3.5287] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 134.9]\n",
      "[Epoch 12/200] [acc : 99.69] [P : 0.0005] [D : 0.2808] [G : 4.2179] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 146.4]\n",
      "[Epoch 13/200] [acc : 99.69] [P : 0.0007] [D : 0.2685] [G : 3.8142] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 158.0]\n",
      "[Epoch 14/200] [acc : 99.58] [P : 0.0016] [D : 0.1563] [G : 4.4799] [info: 0.3133] [code P: 0.0001] [code G: 0.0000] [time: 169.6]\n"
     ]
    }
   ],
   "source": [
    "image_one = x[8].unsqueeze(0).clone()\n",
    "image_seven = x[9].unsqueeze(0).clone()\n",
    "\n",
    "import torchvision\n",
    "from torch.utils import tensorboard\n",
    "today = datetime.date.today()\n",
    "loss_writer = tensorboard.SummaryWriter('logs/MNIST/loss/{}_{}'.format(today,args['description']))\n",
    "image_writer = tensorboard.SummaryWriter('logs/MNIST/image/{}_{}'.format(today,args['description']))\n",
    "\n",
    "start = time.time() ; print('Training starts!')\n",
    "\n",
    "for epoch in range(args['Epochs']):\n",
    "    M.train() ; P.train() ; G.train() ; D.train()\n",
    "    for i, (imgs,labels) in enumerate(train_loader):\n",
    "        batch_size = imgs.shape[0]\n",
    "        real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "        \n",
    "        real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "        real_labels = to_discrete(labels.numpy(), args['n_classes']).to(device)\n",
    "        labels = labels.to(device)\n",
    "        encoded = E(real_imgs)        \n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Predictor\n",
    "        # -----------------\n",
    "        optimizer_P.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        predicted= P(code_P)\n",
    "        loss_P = predict_loss(predicted, real_labels)\n",
    "\n",
    "        loss_P.backward(retain_graph=True)\n",
    "        optimizer_P.step()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        fake_imgs = G(real_labels, code_P, code_G, latent)\n",
    "        reality, _, _, _ = D(fake_imgs)\n",
    "        \n",
    "        loss_adv = adversarial_loss(reality, real) # fake_imgs의 분류(D) 결과가 최대한 1(real)로 분류되도록 G 학습\n",
    "        loss_recon = recon_loss(real_imgs, fake_imgs)\n",
    "        # alpha = 0.1\n",
    "        # loss_G = (alpha*loss_adv + (1-alpha)*loss_recon)\n",
    "        loss_G = (loss_adv + 100*loss_recon)\n",
    "        loss_G.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "    \n",
    "        # -----------------\n",
    "        #  Train Discriminator\n",
    "        # -----------------\n",
    "        optimizer_D.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        # real or fake pred score\n",
    "        pred_real, _, _, _ = D(real_imgs)\n",
    "        pred_fake, _, _, _ = D(fake_imgs.detach())\n",
    "        loss_D_real = adversarial_loss(pred_real, real) # real_imgs는 D가 1(real)로 분류하도록 D 학습 \n",
    "        loss_D_fake = adversarial_loss(pred_fake, fake) # fake_imgs는 D가 0(fake)로 분류하도록 D 학습\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "        \n",
    "        loss_D.backward(retain_graph=True)\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ------------------\n",
    "        # Information Loss\n",
    "        # ------------------\n",
    "        if epoch > 50:\n",
    "            optimizer_info.zero_grad()\n",
    "            code_P, code_G, latent = M(encoded.clone())\n",
    "            predicted = P(code_P)\n",
    "            fake_imgs = G(real_labels, code_P, code_G, latent)\n",
    "            _, pred_label, pred_code_P, pred_code_G = D(fake_imgs) # D라고 해놨지만 Q head의 출력임\n",
    "            # pred_label = Variable(LongTensor(to_np(pred_label))).to(device)\n",
    "            # labels = Variable(LongTensor(to_np(labels))).to(device)\n",
    "            \n",
    "            loss_info_disc = lambda_disc * discrete_loss(pred_label, real_labels) # 실제 레이블 예측(이산 CELoss)\n",
    "            loss_info_code_P = lambda_code * code_loss(pred_code_P.clone(), code_P.clone()) # code_P 예측 (연속 MSELoss\n",
    "            loss_info_code_G = lambda_code * code_loss(pred_code_G, code_G) # code_G 예측(연속 MSELoss)\n",
    "            loss_info =  loss_info_disc + loss_info_code_P + loss_info_code_G\n",
    "            \n",
    "            loss_info.backward(retain_graph=True)\n",
    "            optimizer_info.step()\n",
    "            \n",
    "    # --------------\n",
    "    # Log Progress\n",
    "    # --------------\n",
    "    M.eval() ; P.eval() ; G.eval() ; D.eval()\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for test_image, test_label in test_loader:\n",
    "            batch_size = test_image.shape[0]\n",
    "            test_image = test_image.to(device)\n",
    "            test_label = test_label.to(device)\n",
    "            code_P, code_G, latent = M(E(test_image).clone())\n",
    "            output = P(code_P).to(device)\n",
    "            prediction = output.max(1,keepdim=True)[1].to(device)\n",
    "            correct += prediction.eq(test_label.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_accuracy = 100*correct / len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [acc : %.2f] [P : %.4f] [D : %.4f] [G : %.4f] [info: %.4f] [code P: %.4f] [code G: %.4f] [time: %.1f]\"\n",
    "        % (epoch, args['Epochs'],\n",
    "           test_accuracy,\n",
    "        #    i, len(train_loader),\n",
    "           loss_P.item(),\n",
    "           loss_D.item(), \n",
    "           loss_G.item(), \n",
    "           loss_info.item(),\n",
    "           loss_info_code_P.item(),\n",
    "           loss_info_code_G.item(),\n",
    "           time.time()-start)\n",
    "    )\n",
    "    \n",
    "    sample, grid = sample_image(epoch=epoch)\n",
    "    \n",
    "    image_writer.add_image('sample', grid, epoch)\n",
    "    loss_writer.add_scalar('loss_P', loss_P.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_D', loss_D.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_G', loss_G.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info', loss_info.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_d', loss_info_disc.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_code_P', loss_info_code_P.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_code_G', loss_info_code_G.item(), epoch)\n",
    "    loss_writer.add_scalar('accuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_one = x[25].unsqueeze(0).clone()\n",
    "image_seven = x[10].unsqueeze(0).clone()\n",
    "sample_image(300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (imgs,labels) in enumerate(train_loader):\n",
    "    batch_size = imgs.shape[0]\n",
    "    real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "    fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "    \n",
    "    real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "    real_labels = to_discrete(labels.numpy(), args['n_classes']).to(device)\n",
    "    labels = labels.to(device)\n",
    "    encoded = E(real_imgs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc : torch.Size([10, 2])\n",
      "inter_p : torch.Size([10, 3])\n",
      "inter_g1 : torch.Size([10, 3])\n",
      "inter_g2 : torch.Size([10, 3])\n",
      "latent : torch.Size([10, 32])\n",
      "one_p_latent : torch.Size([10, 37])\n",
      "sample : torch.Size([10, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# print('disc :', one_repeat.shape)\n",
    "# print('inter_p :', inter_p.shape)\n",
    "# print('inter_g1 :', inter_g1.shape)\n",
    "# print('inter_g2 :', inter_g2.shape)\n",
    "# print('latent :', latent_repeat.shape)\n",
    "# print('one_p_latent :', torch.cat([one_repeat, inter_p, latent_repeat], dim=-1).shape)\n",
    "# print('sample :', sample_one.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([1, 2]) torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "print(code_P.shape, code_G.shape, latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# torch.save(E, 'pretrained_model/main/first_success_E.pt')\n",
    "# torch.save(P, 'pretrained_model/main/first_success_P.pt')\n",
    "# torch.save(G, 'pretrained_model/main/first_success_G.pt')\n",
    "# torch.save(D, 'pretrained_model/main/first_success_D.pt')\n",
    "\n",
    "# torch.save(E.state_dict(), '{}/pretrained_model/main/first_success_E_state.pt')\n",
    "# torch.save(P.state_dict(), 'pretrained_model/main/first_success_P_state.pt')\n",
    "# torch.save(G.state_dict(), 'pretrained_model/main/first_success_G_state.pt')\n",
    "# torch.save(D.state_dict(), 'pretrained_model/main/first_success_D_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "997969026bb0563814df38f7ef8affc802fa04c571d985f23020a609d23c35a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('opcode': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
