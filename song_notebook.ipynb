{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "오늘 날짜 : 2022-02-11\n",
      "GPU device : cuda:2\n",
      "image.size() =  torch.Size([128, 1, 32, 32]) \ttype torch.FloatTensor\n",
      "label.size() =  torch.Size([128]) \ttype torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "args = {\n",
    "        'GPU_NUM' : 2,\n",
    "        'Epochs' : 200,\n",
    "        'batch_size' : 128,\n",
    "        'lr' : 0.0002,\n",
    "        'b1' : 0.5,\n",
    "        'b2' : 0.999,\n",
    "        'latent_dim' : 62,\n",
    "        'code_dim' : 2,\n",
    "        'n_classes' : 2,\n",
    "        'img_size' : 32,\n",
    "        'channels' : 1,\n",
    "        'sample_interval' : 400\n",
    "        }\n",
    "\n",
    "device = torch.device('cuda:{}'.format(args['GPU_NUM']) if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "today = datetime.date.today()\n",
    "print('오늘 날짜 :',today)\n",
    "print('GPU device :', device)\n",
    "\n",
    "my_transform =transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(args['img_size']), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_data = ImageFolder('MNIST/classes/binary/train', transform = my_transform)\n",
    "test_data = ImageFolder('MNIST/classes/binary/test', transform = my_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=args['batch_size'], shuffle=True)\n",
    "\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10*pltsize,pltsize))\n",
    "for image, label in train_loader:\n",
    "    print('image.size() = ',image.size(), '\\ttype', image.type())\n",
    "    print('label.size() = ', label.size(), '\\ttype', label.type())\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(10*pltsize,pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image[i,:,:,:].permute(1,2,0), cmap=\"gray\")\n",
    "    plt.title('class '+ str(label[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    \"\"\" Conv layer는 mean이 0, std가 0.02인 가우시안 분포로 weight init\n",
    "        BatchNorm은 mean이 1, std가 0.02인 가우시안 분포로 weight init\n",
    "        Bias term은 전부 0으로 초기화\n",
    "    Args:\n",
    "        m ([model]): 학습하려는 모델\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def to_discrete(y, num_columns):\n",
    "    \"\"\" onehot encoding\n",
    "        (batch_size,)가 shape인 label이 있으면, (64,num_columns)인 zeros 행렬을 생성하고,\n",
    "        (batch_size,)의 label vector element 값의 index만 1로 바꿔서 one-hot encoding함\n",
    "    Args:\n",
    "        y : 어떤 array (y.shape[0]는 batch_size로 보면 됨)\n",
    "        num_columns : num_classes\n",
    "    \"\"\"\n",
    "    y_disc = np.zeros((y.shape[0], num_columns))\n",
    "    y_disc[range(y.shape[0]), y] = 1.0 # one-hot encoding()\n",
    "\n",
    "    return Variable(FloatTensor(y_disc))\n",
    "\n",
    "def sample_image(epoch):\n",
    "    folder_path = datetime.date.today()\n",
    "    os.makedirs('samples/{}_{}'.format(folder_path,args['description']), exist_ok=True)\n",
    "\n",
    "    inter = torch.linspace(-2,2,10).unsqueeze(1).to(device)\n",
    "   \n",
    "    # one !!\n",
    "    true_p, true_g, latent = M(E(image_one))\n",
    "    inter_p = inter\n",
    "    inter_g0 = torch.cat([inter, true_g[0, 1].unsqueeze(0).repeat(10,1)], dim=-1).to(device)\n",
    "    inter_g1 = torch.cat([true_g[0, 0].unsqueeze(0).repeat(10,1), inter], dim=-1).to(device)\n",
    "    label_one = torch.tensor([1,0], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    one_repeat = label_one.repeat(10,1).to(device)\n",
    "    one_latent_repeat = latent.repeat(10,1).to(device)\n",
    "    one_p = G(one_repeat, inter_p, true_g.repeat(10,1), one_latent_repeat)\n",
    "    one_g1 = G(one_repeat, true_p.repeat(10,1), inter_g0, one_latent_repeat)\n",
    "    one_g2 = G(one_repeat, true_p.repeat(10,1), inter_g1, one_latent_repeat)\n",
    "    sample_one = torch.cat([image_one,one_p, image_one,one_g1, image_one,one_g2], dim=0).to(device)\n",
    "\n",
    "    # seven!!!\n",
    "    true_p, true_g, latent = M(E(image_seven))\n",
    "    inter_p = inter\n",
    "    inter_g0 = torch.cat([inter, true_g[0, 1].unsqueeze(0).repeat(10,1)], dim=-1).to(device)\n",
    "    inter_g1 = torch.cat([true_g[0, 0].unsqueeze(0).repeat(10,1), inter], dim=-1).to(device)\n",
    "    label_seven = torch.tensor([0,1], dtype=torch.int64, device=device).unsqueeze(0)\n",
    "    seven_repeat = label_seven.repeat(10,1).to(device)\n",
    "    seven_latent_repeat = latent.repeat(10,1).to(device)\n",
    "    seven_p = G(seven_repeat, inter_p, true_g.repeat(10,1), seven_latent_repeat)\n",
    "    seven_g1 = G(seven_repeat, true_p.repeat(10,1), inter_g0, seven_latent_repeat)\n",
    "    seven_g2 = G(seven_repeat, true_p.repeat(10,1), inter_g1, seven_latent_repeat)\n",
    "    sample_seven = torch.cat([image_seven,seven_p,image_seven,seven_g1, image_seven,seven_g2], dim=0).to(device)\n",
    "    \n",
    "    sample = torch.cat([sample_one,sample_seven], dim=0).to(device)\n",
    "        \n",
    "    grid = torchvision.utils.make_grid(sample, nrow=11, normalize=True)\n",
    "    \n",
    "    save_image(grid, 'samples/{}_{}/grid_{}.png'.format(folder_path,args['description'],epoch))\n",
    "    \n",
    "    return sample, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_loss = nn.CrossEntropyLoss().to(device)\n",
    "recon_loss = nn.MSELoss().to(device)\n",
    "adversarial_loss = nn.MSELoss().to(device)\n",
    "discrete_loss = nn.CrossEntropyLoss().to(device)\n",
    "code_loss = nn.MSELoss().to(device)\n",
    "# code_loss_P = nn.MSELoss().to(device)\n",
    "# pred_P_D_loss = nn.L1Loss().to(device)\n",
    "\n",
    "lambda_disc = 1\n",
    "lambda_code = 0.5\n",
    "\n",
    "from pretrain_ResNet import ResNet_3232\n",
    "pretrained_resnet = ResNet_3232(channels=1, num_classes=2).to(device)\n",
    "pretrained_resnet.load_state_dict(torch.load('pretrained_model/ResNet_3232_parameters_1_7.pt'))\n",
    "\n",
    "args['disc_dim'] = 2\n",
    "args['code_P_dim'] = 1\n",
    "args['code_G_dim'] = 2\n",
    "args['latent_dim'] = 32\n",
    "args['reduced_dim'] = args['code_P_dim'] + args['code_G_dim'] + args['latent_dim'] # 35\n",
    "\n",
    "from StyleInfoGAN import *\n",
    "E = nn.Sequential(*(list(pretrained_resnet.children())[:5])).to(device)\n",
    "M = Mapper(args).to(device)\n",
    "P = Predictor(args).to(device)\n",
    "G = Generator(args).to(device)\n",
    "D = Discriminator(args).to(device)\n",
    "\n",
    "\n",
    "M.apply(weights_init_normal)\n",
    "P.apply(weights_init_normal)\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizer_P = torch.optim.Adam(itertools.chain(M.parameters(),P.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(M.parameters(),G.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_D = torch.optim.Adam(itertools.chain(M.parameters(),D.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_info = torch.optim.Adam(itertools.chain(M.parameters(), P.parameters(),G.parameters(), D.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "# optimizer_info_P = torch.optim.Adam(itertools.chain(M.parameters(), P.parameters(), G.parameters(), D.parameters()), \n",
    "#                                     lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if (device == 'cuda:{}'.format(args['GPU_NUM'])) else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if (device == 'cuda:{}'.format(args['GPU_NUM'])) else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_loader:\n",
    "#     x = x.to(device)\n",
    "#     y = y.to(device)\n",
    "#     break\n",
    "\n",
    "# plt.figure(figsize=(15,12))\n",
    "# for idx in range(20):\n",
    "#     plt.subplot(4,5,idx+1)\n",
    "#     plt.axis('off')\n",
    "#     plt.title('idx={}, label={}'.format(idx, y[idx].item()))\n",
    "#     plt.imshow(to_np(x[idx].permute(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts!\n"
     ]
    }
   ],
   "source": [
    "image_one = x[13].unsqueeze(0).clone()\n",
    "image_seven = x[0].unsqueeze(0).clone()\n",
    "\n",
    "import torchvision\n",
    "from torch.utils import tensorboard\n",
    "\n",
    "args['description'] = 'StyleInfoGAN second try'\n",
    "today = datetime.date.today()\n",
    "loss_writer = tensorboard.SummaryWriter('logs/MNIST/loss/{}_{}'.format(today,args['description']))\n",
    "image_writer = tensorboard.SummaryWriter('logs/MNIST/image/{}_{}'.format(today,args['description']))\n",
    "\n",
    "start = time.time() ; print('Training starts!')\n",
    "\n",
    "for epoch in range(args['Epochs']):\n",
    "    M.train() ; P.train() ; G.train() ; D.train()\n",
    "    for i, (imgs,labels) in enumerate(train_loader):\n",
    "        batch_size = imgs.shape[0]\n",
    "        real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "        \n",
    "        real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "        real_labels = to_discrete(labels.numpy(), args['n_classes']).to(device)\n",
    "        labels = labels.to(device)\n",
    "        encoded = E(real_imgs)        \n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Predictor\n",
    "        # -----------------\n",
    "        optimizer_P.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        predicted= P(code_P)\n",
    "        loss_P = predict_loss(predicted, real_labels)\n",
    "\n",
    "        loss_P.backward(retain_graph=True)\n",
    "        optimizer_P.step()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        fake_imgs = G(real_labels, code_P, code_G, latent)\n",
    "        reality, _, _, _ = D(fake_imgs)\n",
    "        \n",
    "        loss_adv = adversarial_loss(reality, real) # fake_imgs의 분류(D) 결과가 최대한 1(real)로 분류되도록 G 학습\n",
    "        loss_recon = recon_loss(real_imgs, fake_imgs)\n",
    "        # alpha = 0.1\n",
    "        # loss_G = (alpha*loss_adv + (1-alpha)*loss_recon)\n",
    "        loss_G = (loss_adv + 100*loss_recon)\n",
    "        loss_G.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "    \n",
    "        # -----------------\n",
    "        #  Train Discriminator\n",
    "        # -----------------\n",
    "        optimizer_D.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        # real or fake pred score\n",
    "        pred_real, _, _, _ = D(real_imgs)\n",
    "        pred_fake, _, _, _ = D(fake_imgs.detach())\n",
    "        loss_D_real = adversarial_loss(pred_real, real) # real_imgs는 D가 1(real)로 분류하도록 D 학습 \n",
    "        loss_D_fake = adversarial_loss(pred_fake, fake) # fake_imgs는 D가 0(fake)로 분류하도록 D 학습\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "        \n",
    "        loss_D.backward(retain_graph=True)\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ------------------\n",
    "        # Information Loss\n",
    "        # ------------------\n",
    "        optimizer_info.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        predicted = P(code_P)\n",
    "        fake_imgs = G(real_labels, code_P, code_G, latent)\n",
    "        _, pred_label, pred_code_P, pred_code_G = D(fake_imgs) # D라고 해놨지만 Q head의 출력임\n",
    "        # pred_label = Variable(LongTensor(to_np(pred_label))).to(device)\n",
    "        # labels = Variable(LongTensor(to_np(labels))).to(device)\n",
    "        \n",
    "        loss_info_disc = lambda_disc * discrete_loss(pred_label, real_labels) # 실제 레이블 예측(이산 CELoss)\n",
    "        loss_info_code_P = lambda_code * code_loss(pred_code_P.clone(), code_P.clone()) # code_P 예측 (연속 MSELoss\n",
    "        loss_info_code_G = lambda_code * code_loss(pred_code_G, code_G) # code_G 예측(연속 MSELoss)\n",
    "        loss_info =  loss_info_disc + loss_info_code_P + loss_info_code_G\n",
    "        \n",
    "        loss_info.backward(retain_graph=True)\n",
    "        optimizer_info.step()\n",
    "            \n",
    "    # --------------\n",
    "    # Log Progress\n",
    "    # --------------\n",
    "    M.eval() ; P.eval() ; G.eval() ; D.eval()\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for test_image, test_label in test_loader:\n",
    "            batch_size = test_image.shape[0]\n",
    "            test_image = test_image.to(device)\n",
    "            test_label = test_label.to(device)\n",
    "            code_P, code_G, latent = M(E(test_image).clone())\n",
    "            output = P(code_P).to(device)\n",
    "            prediction = output.max(1,keepdim=True)[1].to(device)\n",
    "            correct += prediction.eq(test_label.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_accuracy = 100*correct / len(test_loader.dataset)\n",
    "    if epoch % 5 == 0:\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [acc : %.2f] [P : %.4f] [D : %.4f] [G : %.4f] [info: %.4f] [code P: %.4f] [code G: %.4f] [time: %.1f]\"\n",
    "            % (epoch, args['Epochs'],\n",
    "            test_accuracy,\n",
    "            #    i, len(train_loader),\n",
    "            loss_P.item(),\n",
    "            loss_D.item(), \n",
    "            loss_G.item(), \n",
    "            loss_info.item(),\n",
    "            loss_info_code_P.item(),\n",
    "            loss_info_code_G.item(),\n",
    "            time.time()-start)\n",
    "        )\n",
    "    \n",
    "    sample, grid = sample_image(epoch=epoch)\n",
    "    \n",
    "    image_writer.add_image('sample', grid, epoch)\n",
    "    loss_writer.add_scalar('loss_P', loss_P.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_D', loss_D.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_G', loss_G.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info', loss_info.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_d', loss_info_disc.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_code_P', loss_info_code_P.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_code_G', loss_info_code_G.item(), epoch)\n",
    "    loss_writer.add_scalar('accuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_one = x[25].unsqueeze(0).clone()\n",
    "image_seven = x[10].unsqueeze(0).clone()\n",
    "sample_image(300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (imgs,labels) in enumerate(train_loader):\n",
    "    batch_size = imgs.shape[0]\n",
    "    real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "    fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "    \n",
    "    real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "    real_labels = to_discrete(labels.numpy(), args['n_classes']).to(device)\n",
    "    labels = labels.to(device)\n",
    "    encoded = E(real_imgs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "997969026bb0563814df38f7ef8affc802fa04c571d985f23020a609d23c35a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('opcode': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
