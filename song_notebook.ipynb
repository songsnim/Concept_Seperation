{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날짜 : 2022-02-14\n",
      "GPU device : cuda:2\n",
      "image.size() =  torch.Size([128, 1, 32, 32]) \ttype torch.FloatTensor\n",
      "label.size() =  torch.Size([128]) \ttype torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "args = {\n",
    "        'GPU_NUM' : 2,\n",
    "        'Epochs' : 200,\n",
    "        'batch_size' : 128,\n",
    "        'lr' : 0.0002,\n",
    "        'b1' : 0.5,\n",
    "        'b2' : 0.999,\n",
    "        'latent_dim' : 62,\n",
    "        'code_dim' : 2,\n",
    "        'n_classes' : 2,\n",
    "        'img_size' : 32,\n",
    "        'channels' : 1,\n",
    "        'sample_interval' : 400\n",
    "        }\n",
    "\n",
    "device = torch.device('cuda:{}'.format(args['GPU_NUM']) if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "today = datetime.date.today()\n",
    "print('오늘 날짜 :',today)\n",
    "print('GPU device :', device)\n",
    "\n",
    "my_transform =transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(args['img_size']), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_data = ImageFolder('MNIST/classes/binary/train', transform = my_transform)\n",
    "test_data = ImageFolder('MNIST/classes/binary/test', transform = my_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=args['batch_size'], shuffle=True)\n",
    "\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10*pltsize,pltsize))\n",
    "for image, label in train_loader:\n",
    "    print('image.size() = ',image.size(), '\\ttype', image.type())\n",
    "    print('label.size() = ', label.size(), '\\ttype', label.type())\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(10*pltsize,pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image[i,:,:,:].permute(1,2,0), cmap=\"gray\")\n",
    "    plt.title('class '+ str(label[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    \"\"\" Conv layer는 mean이 0, std가 0.02인 가우시안 분포로 weight init\n",
    "        BatchNorm은 mean이 1, std가 0.02인 가우시안 분포로 weight init\n",
    "        Bias term은 전부 0으로 초기화\n",
    "    Args:\n",
    "        m ([model]): 학습하려는 모델\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def to_discrete(y, num_columns):\n",
    "    \"\"\" onehot encoding\n",
    "        (batch_size,)가 shape인 label이 있으면, (64,num_columns)인 zeros 행렬을 생성하고,\n",
    "        (batch_size,)의 label vector element 값의 index만 1로 바꿔서 one-hot encoding함\n",
    "    Args:\n",
    "        y : 어떤 array (y.shape[0]는 batch_size로 보면 됨)\n",
    "        num_columns : num_classes\n",
    "    \"\"\"\n",
    "    y_disc = np.zeros((y.shape[0], num_columns))\n",
    "    y_disc[range(y.shape[0]), y] = 1.0 # one-hot encoding()\n",
    "\n",
    "    return Variable(FloatTensor(y_disc))\n",
    "\n",
    "def sample_image(epoch):\n",
    "    folder_path = datetime.date.today()\n",
    "    os.makedirs('samples/{}_{}'.format(folder_path,args['description']), exist_ok=True)\n",
    "\n",
    "    inter = torch.linspace(-2,2,10).unsqueeze(1).to(device)\n",
    "   \n",
    "    # one !!\n",
    "    true_p, true_g, latent = M(E(image_one))\n",
    "    one_recon = G(true_p, true_g, latent)\n",
    "    inter_p = inter\n",
    "    inter_g0 = torch.cat([inter, true_g[0, 1].unsqueeze(0).repeat(10,1)], dim=-1).to(device)\n",
    "    inter_g1 = torch.cat([true_g[0, 0].unsqueeze(0).repeat(10,1), inter], dim=-1).to(device)\n",
    "    one_latent_repeat = latent.repeat(10,1).to(device)\n",
    "\n",
    "    one_p = G(inter_p, true_g.repeat(10,1), one_latent_repeat)\n",
    "    one_g1 = G(true_p.repeat(10,1), inter_g0, one_latent_repeat)\n",
    "    one_g2 = G(true_p.repeat(10,1), inter_g1, one_latent_repeat)\n",
    "    \n",
    "    sample_one = torch.cat([image_one, one_recon, one_p, \n",
    "                            image_one, one_recon, one_g1, \n",
    "                            image_one, one_recon, one_g2], dim=0).to(device)\n",
    "\n",
    "    # seven!!!\n",
    "    true_p, true_g, latent = M(E(image_seven))\n",
    "    seven_recon = G(true_p, true_g, latent)\n",
    "    inter_p = inter\n",
    "    inter_g0 = torch.cat([inter, true_g[0, 1].unsqueeze(0).repeat(10,1)], dim=-1).to(device)\n",
    "    inter_g1 = torch.cat([true_g[0, 0].unsqueeze(0).repeat(10,1), inter], dim=-1).to(device)\n",
    "    seven_latent_repeat = latent.repeat(10,1).to(device)\n",
    "    \n",
    "    seven_p = G(inter_p, true_g.repeat(10,1), seven_latent_repeat)\n",
    "    seven_g1 = G(true_p.repeat(10,1), inter_g0, seven_latent_repeat)\n",
    "    seven_g2 = G(true_p.repeat(10,1), inter_g1, seven_latent_repeat)\n",
    "    \n",
    "    sample_seven = torch.cat([image_seven,seven_recon, seven_p,\n",
    "                              image_seven,seven_recon, seven_g1, \n",
    "                              image_seven,seven_recon, seven_g2], dim=0).to(device)\n",
    "    \n",
    "    # aggregate and save\n",
    "    sample = torch.cat([sample_one,sample_seven], dim=0).to(device)\n",
    "    grid = torchvision.utils.make_grid(sample, nrow=11, normalize=True)\n",
    "    save_image(grid, 'samples/{}_{}/grid_{}.png'.format(folder_path,args['description'],epoch))\n",
    "    \n",
    "    return sample, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction criterion\n",
    "predict_loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# adversarial criterion\n",
    "adversarial_loss = nn.MSELoss().to(device)\n",
    "fidelity_loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# reconstruction criterion\n",
    "recon_loss = nn.MSELoss().to(device)\n",
    "recon_loss_E = nn.MSELoss().to(device)\n",
    "fidelity_loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Info criterion\n",
    "code_P_loss = nn.MSELoss().to(device)\n",
    "code_G_loss = nn.MSELoss().to(device)\n",
    "\n",
    "lambda_disc = 1\n",
    "lambda_code = 0.5\n",
    "\n",
    "from pretrain_ResNet import ResNet_3232\n",
    "pretrained_resnet = ResNet_3232(channels=1, num_classes=2).to(device)\n",
    "pretrained_resnet.load_state_dict(torch.load('pretrained_model/ResNet_3232_parameters_1_7.pt'))\n",
    "\n",
    "args['code_P_dim'] = 1\n",
    "args['code_G_dim'] = 2\n",
    "args['latent_dim'] = 32\n",
    "args['reduced_dim'] = args['code_P_dim'] + args['code_G_dim'] + args['latent_dim'] # 35\n",
    "\n",
    "# from StyleInfoGAN import *\n",
    "from Networks import *\n",
    "E = nn.Sequential(*(list(pretrained_resnet.children())[:5])).to(device)\n",
    "M = Mapper(args).to(device)\n",
    "P = Predictor(args).to(device)\n",
    "G = Generator(args).to(device)\n",
    "D = Discriminator(args).to(device)\n",
    "\n",
    "\n",
    "M.apply(weights_init_normal)\n",
    "P.apply(weights_init_normal)\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizer_P = torch.optim.Adam(itertools.chain(M.parameters(),P.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(M.parameters(),G.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_D = torch.optim.Adam(itertools.chain(M.parameters(),D.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "optimizer_info = torch.optim.Adam(itertools.chain(M.parameters(), P.parameters(),G.parameters(), D.parameters()), lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "# optimizer_info_P = torch.optim.Adam(itertools.chain(M.parameters(), P.parameters(), G.parameters(), D.parameters()), \n",
    "#                                     lr=args['lr'], betas=(args['b1'], args['b2']))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if (device == 'cuda:{}'.format(args['GPU_NUM'])) else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if (device == 'cuda:{}'.format(args['GPU_NUM'])) else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_loader:\n",
    "#     x = x.to(device)\n",
    "#     y = y.to(device)\n",
    "#     break\n",
    "\n",
    "# plt.figure(figsize=(15,12))\n",
    "# for idx in range(20):\n",
    "#     plt.subplot(4,5,idx+1)\n",
    "#     plt.axis('off')\n",
    "#     plt.title('idx={}, label={}'.format(idx, y[idx].item()))\n",
    "#     plt.imshow(to_np(x[idx].permute(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts!\n"
     ]
    }
   ],
   "source": [
    "image_one = x[10].unsqueeze(0).clone()\n",
    "image_seven = x[17].unsqueeze(0).clone()\n",
    "\n",
    "import torchvision\n",
    "from torch.utils import tensorboard\n",
    "\n",
    "args['description'] = 'Gazok Orakgwan with M(E()) loss'\n",
    "today = datetime.date.today()\n",
    "loss_writer = tensorboard.SummaryWriter('logs/MNIST/loss/{}_{}'.format(today,args['description']))\n",
    "image_writer = tensorboard.SummaryWriter('logs/MNIST/image/{}_{}'.format(today,args['description']))\n",
    "\n",
    "start = time.time() ; print('Training starts!')\n",
    "\n",
    "for epoch in range(args['Epochs']):\n",
    "    M.train() ; P.train() ; G.train() ; D.train()\n",
    "    for i, (imgs,labels) in enumerate(train_loader):\n",
    "        batch_size = imgs.shape[0]\n",
    "        real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "        \n",
    "        real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "        real_labels = to_discrete(labels.numpy(), args['n_classes']).to(device)\n",
    "        labels = labels.to(device)\n",
    "        encoded = E(real_imgs)        \n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Predictor\n",
    "        # -----------------\n",
    "        optimizer_P.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        predicted= P(code_P)\n",
    "        loss_P = predict_loss(predicted, real_labels)\n",
    "\n",
    "        loss_P.backward(retain_graph=True)\n",
    "        optimizer_P.step()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        real_M_output = torch.cat([code_P, code_G, latent], dim=1)\n",
    "        fake_imgs = G(code_P, code_G, latent)\n",
    "        code_P_fake, code_G_fake, latent_fake = M(E(fake_imgs).clone())\n",
    "        fake_M_output = torch.cat([code_P_fake, code_G_fake, latent_fake], dim=1)\n",
    "        reality, _, _ = D(fake_imgs)\n",
    "        \n",
    "        loss_adv = adversarial_loss(reality, real) # fake_imgs의 분류(D) 결과가 최대한 1(real)로 분류되도록 G 학습\n",
    "        loss_recon = recon_loss(real_imgs, fake_imgs)\n",
    "        loss_recon_E = recon_loss_E(real_M_output, fake_M_output)\n",
    "        loss_fidelity = fidelity_loss(P(code_P), P(code_P_fake))\n",
    "        # alpha = 0.1\n",
    "        # loss_G = (alpha*loss_adv + (1-alpha)*loss_recon)\n",
    "        loss_G = loss_adv + 100*loss_recon + loss_recon_E\n",
    "        loss_G.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "    \n",
    "        # -----------------\n",
    "        #  Train Discriminator\n",
    "        # -----------------\n",
    "        optimizer_D.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        # real or fake pred score\n",
    "        pred_real, _, _ = D(real_imgs.detach())\n",
    "        pred_fake, _, _ = D(fake_imgs.detach())\n",
    "        loss_D_real = adversarial_loss(pred_real, real) # real_imgs는 D가 1(real)로 분류하도록 D 학습\n",
    "        loss_D_fake = adversarial_loss(pred_fake, fake) # fake_imgs는 D가 0(fake)로 분류하도록 D 학습\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "        \n",
    "        loss_D.backward(retain_graph=True)\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ------------------\n",
    "        # Information Loss\n",
    "        # ------------------\n",
    "        optimizer_info.zero_grad()\n",
    "        code_P, code_G, latent = M(encoded.clone())\n",
    "        predicted = P(code_P)\n",
    "        fake_imgs = G(code_P, code_G, latent)\n",
    "        _, pred_code_P, pred_code_G = D(fake_imgs) # D라고 해놨지만 Q head의 출력임\n",
    "        \n",
    "        loss_info_code_P = lambda_code * code_P_loss(pred_code_P.clone(), code_P.clone()) # code_P 예측 (연속 MSELoss)\n",
    "        loss_info_code_G = lambda_code * code_G_loss(pred_code_G, code_G) # code_G 예측(연속 MSELoss)\n",
    "        loss_info =  lambda_code * (loss_info_code_P + loss_info_code_G)\n",
    "        \n",
    "        loss_info.backward(retain_graph=True)\n",
    "        optimizer_info.step()\n",
    "            \n",
    "    # --------------\n",
    "    # Log Progress\n",
    "    # --------------\n",
    "    M.eval() ; P.eval() ; G.eval() ; D.eval()\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for test_image, test_label in test_loader:\n",
    "            batch_size = test_image.shape[0]\n",
    "            test_image = test_image.to(device)\n",
    "            test_label = test_label.to(device)\n",
    "            code_P, code_G, latent = M(E(test_image).clone())\n",
    "            output = P(code_P).to(device)\n",
    "            prediction = output.max(1,keepdim=True)[1].to(device)\n",
    "            correct += prediction.eq(test_label.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_accuracy = 100*correct / len(test_loader.dataset)\n",
    "    if epoch % 5 == 0:\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [acc : %.2f] [P : %.4f] [D : %.4f] [G : %.4f] [info: %.4f] [code P: %.4f] [code G: %.4f] [time: %.1f]\"\n",
    "            % (epoch, args['Epochs'],\n",
    "            test_accuracy,\n",
    "            #    i, len(train_loader),\n",
    "            loss_P.item(),\n",
    "            loss_D.item(), \n",
    "            loss_G.item(), \n",
    "            loss_info.item(),\n",
    "            loss_info_code_P.item(),\n",
    "            loss_info_code_G.item(),\n",
    "            time.time()-start)\n",
    "        )\n",
    "    \n",
    "    sample, grid = sample_image(epoch=epoch)\n",
    "    \n",
    "    image_writer.add_image('sample', grid, epoch)\n",
    "    loss_writer.add_scalar('loss_P', loss_P.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_D', loss_D.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_G', loss_G.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info', loss_info.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_code_P', loss_info_code_P.item(), epoch)\n",
    "    loss_writer.add_scalar('loss_info_code_G', loss_info_code_G.item(), epoch)\n",
    "    loss_writer.add_scalar('accuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_one = x[25].unsqueeze(0).clone()\n",
    "image_seven = x[10].unsqueeze(0).clone()\n",
    "sample_image(300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (imgs,labels) in enumerate(train_loader):\n",
    "    batch_size = imgs.shape[0]\n",
    "    real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "    fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "    \n",
    "    real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "    real_labels = to_discrete(labels.numpy(), args['n_classes']).to(device)\n",
    "    labels = labels.to(device)\n",
    "    encoded = E(real_imgs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "997969026bb0563814df38f7ef8affc802fa04c571d985f23020a609d23c35a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('opcode': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
